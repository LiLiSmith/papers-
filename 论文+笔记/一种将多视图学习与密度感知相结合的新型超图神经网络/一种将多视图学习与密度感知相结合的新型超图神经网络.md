## 一种将多视图学习与密度感知相结合的新型超图神经网络

## 1.读Abstract

### ①问题？

基于图的半监督节点分类已成为模式识别的重要领域，具有重要的研究意义。然而，现有方法通常仅依赖于内在图结构或人工构建的图，这可能导致捕获真实数据相关性的不准确，从而降低下游图神经网络的性能。此外，虽然当前的方法主要利用显式图结构，但在利用密度等隐式信息来增强性能方面仍存在未开发的潜力。

### ②方法&创新点？

本文引入了多视图密度感知超图神经网络（MD-HGNN），这是一种将超图结构和表示学习同时集成在统一架构中的新型双连接模型。MD-HGNN 首先利用多视图超图学习 （MVHL） 网络从多个视图探索最佳超图结构，并受到一致性损失的约束，以提高其泛化性。随后，采用密度感知超图注意力（DAHAT）网络，探索基于密度感知注意力机制的数据点之间的高阶语义相关性。

### ③达到的效果？

跨不同基准数据集的广泛实验验证了所提出的 MD-HGNN 方法的有效性，展示了其在半监督节点分类任务中的卓越性能。

## 2.看Experiment（信息密度第二或最大的部分）

### ①实验环境是如何搭建的？如数据集、测试方法、评估指标等

#### 1. 数据集 

- **不平衡数据集**（用于验证模型对真实常见问题的鲁棒性）：
  - **Scene15**: 15个场景类别的4485张图片，每类样本数200-600不等。
  - **CIFAR10-IBL**: 从CIFAR10改造的不平衡数据集，10个类别，每类100-800个样本。
  - **MNIST-IBL**: 从MNIST改造的不平衡数据集，10个类别，每类100-800个样本。
- **平衡数据集**（用于验证模型在标准场景下的性能）：
  - **CIFAR10**, **MNIST**, **SVHN**: 均为广泛使用的图像数据集，每个类别样本数相同（实验中各取10,000张图片）。

**数据处理**：所有图像都使用预训练CNN（如13层CNN）或原始像素值提取特征向量作为节点初始特征。

**数据划分（半监督设置）**：

- **不平衡数据集**：随机选取**250, 500, 750, 1000**个样本作为带标签样本，500个样本作为验证集，其余为测试集。
- **平衡数据集**：从每个类别中随机选取**50, 100, 200, 300**个样本，总计**500, 1000, 2000, 3000**个带标签样本，每类100个样本（共1000个）作为验证集，其余为测试集。

#### 2. 测试方法

- **任务**：半监督节点分类。
- **流程**：首先为所有方法构建一个基础的k近邻图（k=15）作为输入或初始图结构。模型利用带标签节点和整个图结构进行训练，最终预测未标记节点的类别。
- **运行与报告**：所有实验均独立运行**10次**，报告**平均准确率（Accuracy）** 和**标准差**，以确保结果的统计可靠性。对于不平衡数据集，还额外报告了**F1-score（宏平均和加权平均）**。

#### 3. 评估指标

- **主要指标**：**分类准确率（Accuracy）**。
- **辅助指标（尤其针对不平衡数据）**：**F1-score**，包括**宏平均F1**（平等看待每个类别）和**加权平均F1**（考虑类别样本量），能更好地反映模型在不平衡类别上的性能

### ②作为对比的方法？要么是本领域经典的方法，要么是SOTA方法（state-of-art，当下对于当前研究任务最好的方法）

论文与一系列代表性强的图学习基线方法进行了比较，可分为三类：

1. **经典/基础图神经网络（GNNs）**：
   - **GCN**: 图卷积网络的开创性工作。
   - **GAT**: 引入注意力机制的GNN。
   - **GraphSAGE**: inductive学习的代表性方法。
   - **SGC**: 简化版的GCN。
2. **先进的图神经网络（旨在解决过平滑、鲁棒性等问题）**：
   - **APPNP**: 结合个性化PageRank。
   - **DropEdge**: 随机丢弃边进行数据增强。
   - **GCNII**: 使用初始残差和恒等映射缓解过平滑。
   - **GRAND**: 使用随机传播策略。
   - **ElasticGNN**: 弹性消息传递机制。
3. **超图神经网络（HGNNs）**（与MD-HGNN最相关的对比对象）：
   - **HGNN**: 超图神经网络的奠基性工作。
   - **DHGNN**: 动态超图神经网络。
   - **HCNH**: 在节点和超边上同时进行滤波。
   - **LEGNN**: 标签增强的图神经网络

### ③取得了何种定性或定量效果？ 有些论文还会采用消融实验

#### 1.定量效果

- **在不平衡数据集上**：MD-HGNN在**所有三个不平衡数据集**上，在不同数量的标签下，其**准确率和F1-score均显著且稳定地优于所有基线方法**。这表明MD-HGNN提出的方法对数据分布不平衡问题具有很强的鲁棒性。
- **在平衡数据集上**：MD-HGNN在CIFAR10和SVHN上表现最佳，在MNIST上也具有高度竞争力。特别是在**标签数量较少（如500）** 的情况下，MD-HGNN的优势更明显，说明其能更有效地利用有限的监督信息。

#### 2. 定性效果

论文通过**t-SNE可视化**在MNIST数据集上学习了节点特征的二维分布。定性结果显示：

- 与基线方法相比，MD-HGNN学习到的**同类节点特征更加紧凑**，**不同类别的簇之间分离得更清晰**。
- 这直观地证明了MD-HGNN能够学习到**判别性更强、质量更高的节点表示**。

#### 3. 消融实验总结

消融实验旨在验证MD-HGNN中两个核心组件的必要性：

1. **多视图超图学习网络（MVHL）的有效性**：
   - **对比设置**：MD-HGNN w/o HGL（不使用MVHL，仅使用原始k-NN超图） vs. MD-HGNN w/i HGL（完整模型）。
   - **结果**：使用MVHL网络在**所有数据集**上均带来了性能提升（最高提升达4.35%），并且**降低了标准差**。这表明学习一个自适应的、多视图的超图结构比依赖固定的原始图更优。
2. **密度感知注意力机制（DAHAT）的有效性**：
   - **对比设置**：MD-HGNN w/o Density（将密度感知注意力替换为普通注意力） vs. MD-HGNN w/i Density（完整模型）。
   - **结果**：引入密度信息后，模型性能**一致提升**（最高提升达1.26%），同时**显著降低了预测结果的标准差**。这证明密度信息能引导模型进行更稳定、更准确的邻居聚合。



## 3.读Introduction（详细版摘要、阐述问题背景、前人的困难、提出本文的原因等）

#### 之前的问题：

1. **图结构依赖性强且不准确**
   - 现有的GNN和HGNN方法严重依赖于输入的图结构（如引用网络、k-NN图等），但这些结构往往是**固有或人工构建的**，并不能保证是最优的。
   - 原始图结构可能包含**冗余或缺失的边**，无法准确反映数据之间的真实关联，从而影响模型性能。
2. **忽视隐式信息（如密度信息）**
   - 大多数方法只利用**显式图结构信息**，而忽略了数据中蕴含的**隐式信息**（如节点密度）。
   - 尽管已有研究尝试使用密度信息，但它们仍局限于**普通图结构**，未能有效捕捉**高阶语义关系**。

#### 如何解决（贡献）：

1. **提出MD-HGNN模型**
   - 一种**双连接模型**，将**超图结构学习**和**超图表示学习**集成在一个统一的架构中。
2. **多视图超图学习网络（MVHL）**
   - 从多个视角学习最优超图结构，每个视角使用**不同的可学习相似性度量**（如余弦相似度、内积）。
   - 引入**一致性损失**，提升超图结构的泛化能力，避免过拟合。
3. **密度感知超图注意力网络（DAHAT）**
   - 提出**超图密度规则**，将密度信息融入注意力机制。
   - 通过**密度感知的注意力权重**，更准确地聚合邻居特征，增强节点和超边的表示能力。
4. **针对不平衡数据的优化**
   - 理论上分析了MD-HGNN在**不平衡数据集**上的优势，并在多个不平衡数据集上验证其优越性。

## 4.读Approach（细节性推导和算法等的具体实现）

### 4.1自适应地学习一个最优的超图结构

------

**公式 (1): 特征嵌入**

- $$
  Xˉ=XW^E
  $$

------

**公式 (2): 多视图相似度计算**
$$
S_{i,j}^{(k)}=sim_k(xˉ_i,xˉ_j)
$$

- **目的**：在嵌入空间的基础上，从第 k个“视角”来计算每两个节点之间的相似度。

- **推导与得到**：
  
  - 论文假设单一的相似度度量（如只使用欧氏距离或只使用余弦相似度）可能无法全面捕捉复杂的数据关系。
  
  - 因此，它设置了 V个不同的视图，在每个视图上使用一种特定的相似度函数 simk(⋅,⋅)。eg：View 1 使用余弦相似度，View 2 使用内积相似度。
  
    **余弦相似度：**
    $$
    sim_{cosine}(xˉ_i,xˉ_j)=\frac{xˉ_i⋅xˉ_j}{∥xˉ_i∥∥xˉ_j∥}
    $$
    **内积（点积）：**
    $$
    sim_{inner}(x_i,x_j)=x_i·x_j=x_i^Tx_j
    $$
    
  - 对于第 k视图，遍历所有节点对 (i,j)，用对应的相似度函数计算它们嵌入特征 xˉi和 xˉj的相似值，最终得到一个完整的相似度矩阵 S(k)∈R^{n×n}。
  
- **作用**：
  
  - **多角度度量**：克服单一相似度度量的局限性，从不同角度挖掘节点间的关系。
  - **增强鲁棒性**：综合多个视图的信息，使得最终学习到的超图结构更加稳定和全面。

------

**公式 (3): 稀疏化处理**
$$
S_{i,j}^{(k)}=\begin{cases}
S_{i,j}^{(k)},S_{i,j}^{(k)}>=δ1\\
0,S_{i,j}^{(k)}<δ1
\end{cases}
$$

- **目的**：将全连接的相似度矩阵 S(k）进行稀疏化，只保留显著强的连接，降低计算复杂度并减少噪声边的干扰。
- **推导与得到**：
  - 设定一个阈值 δ1。这个阈值是一个超参数，需要预先设定或通过验证集调整。
  - 对于相似度矩阵中的每一个元素 Si,j(k)，如果它的值大于等于 δ1，则认为节点 和 j在这个视图下是显著相似的，予以保留。
  - 如果小于 δ1，则认为相似度较弱，可能是噪声或无意义连接，将其置为0。
- **作用**：
  - **计算效率**：稀疏矩阵的存储和运算效率远高于稠密矩阵。
  - **去噪**：过滤掉不可靠的弱连接，使构建出的超图结构更干净。

------

**公式 (4): 超边构造**
$$
H^{(k)}=C_{tt}(S~^{(k)})
$$



- **目的**：将稀疏化的成对相似度矩阵 S~(k)转化为超图的关联矩阵 H(k)。超边可以连接多个节点。
- **推导与得到**：
  - 函数 Ctt(⋅)是“Construct”的缩写，代表一种构造规则。一种常见的规则是：**将每个节点视为一个中心，将其与所有相似度非零的邻居节点连接起来，形成一个超边**。
  - 例如，对于节点 vi，找出所有满足 S~i,j(k)>0 的节点 vj，这些节点和 vi 共同构成一个超边 ei。那么在关联矩阵 H(k)中，Hj,i=1 表示节点 vj这样，会构造出 m=n个超边（每个节点生成一个超边）。当然也可以采用其他策略，如KNN方法为每个节点找Top-K邻居构成超边。
- **作用**：
  - **实现从图到超图的转换**：这是最关键的一步，它将传统的成对关系升级为可以表示群体关系的高阶超边。

------

**公式 (5): 多视图融合**
$$
H=1/V∑_{i=1}^VH^{(i)}
$$


- **目的**：将不同视图下学习到的多个超图结构 H(1),H(2),...,H(V)*H*(1),*H*(2),...,*H*(*V*) 融合成一个统一的、更鲁棒的共识超图结构 H^。
- **推导与得到**：
  - 这里采用了最简单的**平均池化**策略。对每个位置 (i,j)(*i*,*j*) 上的值，在所有 V*V* 个视图的关联矩阵中取平均。
  - 由于每个 H(i)*H*(*i*) 是0/1矩阵（或经过归一化），求平均后，H^*H*^ 中的值在 [0,1][0,1] 区间内，可以理解为节点属于某个超边的“平均概率”或“置信度”。
- **作用**：
  - **集成学习**：综合不同视图的优势，得到一个更稳定、更通用的超图结构，避免因某个单一视图的偏差而学得不好的结构。

------

**公式 (6): 一致性损失**
$$
L_{con}=1/V∑_{i=1}^V∥H^{(i)}−H∥_2^2
$$


- **目的**：作为一种正则化手段，约束不同视图学习到的超图结构彼此之间尽可能相似，从而提升模型的泛化能力。
- **推导与得到**：
  - 这个损失函数计算了每个视图下的超图 H(i)*H*(*i*) 与共识超图 H^*H*^ 之间的差异，使用L2范数（欧氏距离）的平方来衡量。
  - 其思想是：如果所有视图都能学到相似的结构，说明这个共识结构是数据中真正存在的、稳定的模式，而不是偶然的噪声。
- **作用**：
  - **正则化**：防止模型过拟合到某个特定视图的噪声上。
  - **利用无标签数据**：这个损失项不依赖于数据标签，因此可以充分利用大量的无标签样本作为弱监督信号来指导超图结构的学习。

------

**公式 (7): 与初始超图融合**
$$
H=ηH+(1−η)H_0
$$


- **目的**：将数据驱动学习到的新超图结构 H^*H*^ 与可能包含有用先验知识的初始超图结构 H0*H*0 结合起来，取长补短。
- **推导与得到**：
  - H0是初始超图，可以是一个已知的内在结构（如引文网络中的合著关系），也可以是一个人构建的k-NN超图。
  - η是一个介于0和1之间的权衡参数。当 η=1时，完全使用学习到的新结构；当 η=0 时，完全依赖初始结构。
- **作用**：
  - **灵活性**：如果初始结构质量很高，可以通过调小 η来更多地利用它；如果初始结构不可靠，则可以通过调大 η来让模型自己学习。
  - **保证基础**：防止学习过程完全偏离数据的基本拓扑。

------

**公式 (8): 超图学习总损失函数**

$$
L_{Learn}=\frac{a}{n^2}tr⁡(Xˉ^⊤LXˉ)+\fracβ{n^2}∥H∥_F^2−\fracγn1⊤log⁡(H1)+\frac{μ}{n^2}L_{con}
$$
（其中 L^ =D_v^{−1/2} HD_e^{−1} H^⊤ D_v^{−1/2} 是超图拉普拉斯矩阵）

这个损失函数由4部分组成，共同指导超图结构的学习：

1. **平滑项**：a/n^2 tr⁡(Xˉ^⊤ L^ Xˉ)
   - **作用**：基于图信号处理理论，要求**在超图上相邻的节点（即属于同一超边的节点）其特征应该相似**。最小化这一项可以使学习到的超图结构更好地体现特征平滑性。

2. **稀疏项**：β/n^2^∥H∥_F^2
   - **作用**：对关联矩阵 H*H* 进行Frobenius范数正则化，**惩罚大的数值，鼓励矩阵稀疏**。一个稀疏的超图意味着每个超边只连接少数相关的节点，这通常更合理且计算高效。

3. **连通性项**：−γ/n1⊤log⁡(H1)

   - **作用**：防止学习到的超图过于破碎。H1计算的是每个超边的度（即连接了多少个节点）。这项鼓励超边有适当的规模，**避免出现太多连接数极少或为零的超边**，确保图的连通性。

   - H ∈ R^(n×m)

     `1 ∈ R^(m×1)` 是一个全为1的列向量

     - `H · 1` 这个矩阵乘法得到的是一个 **`n × 1` 的列向量**。这个向量的第 `i` 个元素是：
       $$
       (H·1)_i=∑_{j=1}^mH_{i,j}
       $$
       表示的是**节点 `v_i` 的度**，即节点 `v_i` 属于多少个超边。

   - **目的**：防止学习到的超图中出现**孤立节点**（度为零的节点）或**无效超边**（不连接任何节点的超边）。

   - **机制**：如果一个节点的度 `d_i` 趋近于0，那么 `log(d_i)` 会趋近于负无穷（-∞），这将导致损失函数急剧增大（因为前面有负号：`-log(d_i)` → +∞）。

4. **一致性损失项**：μ/n^2Lcon

   - **作用**：即前面公式(6)的内容，用于**约束多视图之间的一致性**。

### 4.2密度感知超图注意力网络

#### 4.2.1密度感知注意力顶点聚合

目标：**生成更好的超边表示**（不仅考虑节点与超边的特征相似度，还考虑节点所在区域的**密度**，认为高密度区域的节点（可能更接近类别中心）应获得更高权重）

**公式 (11): 节点密度定义**
$$
ρ_i^V=∑_{vj∈N(vi)}\begin{cases}
sim(x_i^V,x_j^V),if sim(x_i^V,x_j^V)>δ2\\
0,if sim(x_i^V,x_j^V)≤δ2
\end{cases}
$$

- **推导与含义**：
  - **目的**：量化节点 vi 的局部密度。基于一个假设：一个节点周围的相似节点越多、相似度越高，它所在的区域就越密集，该节点越有可能是潜在的中心点。
  - **计算过程**：
    1. N(vi)是节点 vi 的邻居集合。在图中，邻居通常由邻接矩阵定义；在超图上下文中，这指所有与 vi至少在一个超边中共现的节点，或通过k-NN在特征空间中找到的邻居。
    2. 计算 vi与每个邻居 vj的相似度 sim(⋅)
    3. 设定一个阈值 δ2，只对相似度高于 δ2的邻居求和。这避免了将微弱、不可信的相似关系计入密度。
  - **作用**：ρiV值越大，说明节点 vi 处于一个越“紧密”的群落中。

------

**公式 (12): 基础注意力权重**
$$
a_{i,k}=Attention(x_i^VW,x_k^EW)
$$


- **推导与含义**：

  - **目的**：计算在不考虑密度的情况下，节点 vi 对于超边 ek的**原始重要性**。

  - **计算过程**：

    1. **线性变换**：使用一个共享的可学习权重矩阵 W*W* 将节点特征 xiV和超边特征 xkE 投影到同一个新的特征空间，以便进行后续的比较。这是注意力机制的标准操作。

    2. **注意力函数**：Attention(⋅)是一个标准操作。通常的实现是：将两个投影后的向量拼接起来，然后与一个可学习的注意力向量 aV 做点积，最后经过一个LeakyReLU激活函数。即：
       $$
       a_{i,k}=LeakyReLU(a_V^⊤[x_i^VW∥x_k^EW])
       $$
       其中 `||` 表示拼接操作。

       LeakyReLU 是经典 ReLU 激活函数的一个改进变体。它的数学定义非常简单：
       $$
       LeakyReLU(x)=\begin{cases}
       x\space \space \space if\space x>0\\
       αx\space \space if\space x≤0
       \end{cases}
       $$
       其中：

       - x是函数的输入（通常是神经网络中某一层的线性输出）。
       - α 是一个很小的**超参数**，通常设置为 `0.01` 或 `0.1`。它决定了当输入为负数时，输出的"泄露"（leak）有多大。

  - **作用**：捕获基于特征相似性的重要性。如果节点特征与超边特征越“匹配”，ai,k 的值就越高。

------

**公式 (13) & (14): 密度感知的注意力权重**
$$
a_{i,k}^′=a_{i,k}+ρ~_i^V
$$

$$
A_{i,k}^V=\frac{exp⁡(LeakyReLU((x_iV^W∥x_k^EW)a_V)+ρ~_i^V)}{∑_{v_j∈H(e_k)}exp⁡(LeakyReLU((x_j^VW∥x_k^EW)a_V)+ρ~_j^V)}
$$

- **推导与含义**：
  - **目的**：将密度信息整合到注意力权重中，形成最终的、密度感知的注意力系数。
  - **计算过程**：
    1. **密度归一化**：ρ~iV 是节点密度 ρiV 的归一化版本，将其缩放到一个合适的范围（例如，与 ai,k 的数值范围相匹配）。论文提到将其归一化到 [0,max⁡(aV)] 区间。
    2. **线性叠加**：公式(13)展示了核心思想——将归一化后的密度作为一個**偏置项**直接加到原始注意力分数上。**节点密度越高，其总得分 ai,k 就越高**。
    3. **Softmax归一化**：公式(14)是最终形式。它实际上是将公式(12)和公式(13)合并了。分子是 vi*v**i* 的“基础注意力分+密度偏置”，分母是所有与超边 ek*e**k* 相连的节点的“基础注意力分+密度偏置”之和。通过Softmax函数，确保对于每个超边 ek*e**k*，所有相连节点的注意力系数之和为1。
- **作用**：
  - **核心创新**：这使得注意力权重不仅依赖于特征的局部匹配度，还依赖于节点的全局分布结构。
  - **达到效果**：一个节点即使与当前超边的特征相似度稍低，但只要它处于一个高密度区域（可能是更可靠的类别中心），它的重要性也会被提升。反之，一个特征相似但处于稀疏区域（可能是噪声或边界点）的节点，其重要性会被相对抑制。这使模型更鲁棒。

------

**公式 (15): 特征聚合**
$$
Eˉ=σ((A^V)^⊤X^VW)
$$

- **推导与含义**：

  - **目的**：使用计算好的密度感知注意力权重 AV 来聚合节点信息，更新超边的表示。
  - **计算过程**：
    1. **特征变换**：首先对节点特征 X^V进行线性变换（乘以 W），得到更高层的特征表示。
    2. **加权求和**：然后，对于每个超边 ek，将其连接的所有节点的变换后特征，用对应的注意力系数 Ai,kV进行加权求和。这个操作在矩阵形式上就是 (AV)⊤(XVW)。
    3. **激活函数**：最后通过一个非线性激活函数 σ（如ELU），引入非线性，得到更新后的超边特征矩阵 Eˉ。

- **作用**：**生成新的、更丰富的超边表示**。每个超边的表示现在是由其连接的节点信息以一种“密度感知”的智能方式融合而成。

- **σ**具体指的是 **ELU（指数线性单元）** 或类似的现代激活函数（如 ReLU、LeakyReLU）。

  **ELU（Exponential Linear Unit）** 的数学表达式是：
  $$
  ELU(x)=\begin{cases}
  x\space \space if \space\space x>0\\
  α(e^x−1)\space \space \space if \space \space x≤0
  \end{cases}
  $$
  其中 α是一个超参数，通常为 1。

  与 Sigmoid 和 ReLU 相比，ELU 的优势在于：

  - **缓解梯度消失**：对于正输入，它的导数是 1，和 ReLU 一样，能有效传递梯度。
  - **处理负输入**：对于负输入，它有一个平滑的曲线，输出值趋近于 −α−*α*，而不是像 ReLU 那样直接变为 0。这有助于缓解 ReLU 的 **“神经元死亡”** 问题，使得模型的收敛更加稳定。
  - **均值接近零**：ELU 的输出均值更接近 0，这就像 Batch Normalization 一样，能够加速模型训练。

#### 4,2.2密度感知注意力超边聚合

目标：**利用更新后的超边表示，来生成更好的节点表示**。

核心思想是：**一个节点应该从其所在的、更密集、更可靠的超边中吸收更多信息**。

**公式 (16): 超边密度定义**
$$
ρ_k^E=∑_{v_j∈H(e_k)}ρ_j^V
$$

- **推导与含义**：
  - **目的**：定义超边 ek的密度。一个超边的密度反映了它所覆盖的节点区域的总体密集程度。
  - **计算过程**：超边的密度直接定义为**该超边所连接的所有节点的密度之和**。即，遍历超边 ek连接的所有节点 vj∈H(ek)，将它们在公式(11)中计算得到的节点密度 ρjV 累加起来。
- **作用**：
  - **识别重要超边**：一个包含多个高密度节点（可能都是类别中心点）的超边，其本身密度 ρkE*ρ**k**E* 会很高。这样的超边被认为更可能代表一个**语义一致、稳健的群体或概念**。
  - **传递密度信息**：将节点级别的密度信息提升到了超边级别，为后续的超边注意力机制提供依据。

------

**公式 (17): 密度感知的超边注意力权重**
$$
A_{k,i}^E=\frac{exp⁡(LeakyReLU((x_k^EW∥x_i^VW)a_E)+ρ~_k^E)}{ ∑_{e_j∈H(v_i)}exp⁡(LeakyReLU((x_j^EW∥x_i^VW)a_E)+ρ~_j^E)}
$$
**推导与含义**：

- - **目的**：计算在更新节点 vi的表示时，每个与之相连的超边 ek的**重要性权重**。这是一个密度感知的权重。
  - **计算过程**：此公式与公式(14)在结构上完全对称，但角色互换：
    1. **线性变换与拼接**：将超边特征 xkE和节点特征 xiV 用同一个权重矩阵 W 变换后拼接起来。顺序是 `超边特征 || 节点特征`。
    2. **基础注意力分数**：将拼接后的向量与一个专门为超边聚合设计的可学习注意力向量 aE做点积，再通过 LeakyReLU 激活函数，得到基础分数。
    3. **融入密度偏置**：将**归一化后的超边密度** ρ~kE 加到基础分数上。
    4. **Softmax归一化**：对所有连接到节点 vi的超边 ej∈H(vi)进行Softmax归一化，得到最终的注意力系数 Ak,iE。这确保了对于节点 vi，所有相关超边的注意力权重之和为1。
- **作用**：
  - **权重分配**：它决定了在更新节点 vi*v**i* 的特征时，应该从每个相连的超边 ek*e**k* 中汲取多少信息。
  - **密度引导**：如果一个超边密度高（ρ~kE*ρ*~*k**E* 大），意味着它连接的区域语义明确、结构紧凑，那么它在节点特征聚合中的贡献就会被增强。

------

公式 (18): 超边到节点的特征聚合
$$
Xˉ=σ((AE)^⊤Eˉ)
$$


- **推导与含义**：

  - **目的**：使用计算好的密度感知超边注意力权重 AE，来聚合超边信息，从而更新所有节点的表示。

  - **计算过程**：

    1. Eˉ∈R{m×d} 是来自公式(15)的、已经通过节点信息增强过的超边特征矩阵。

    2. 注意力矩阵 AE∈R{m×n}，其中 Ak,iE表示超边 ek对节点 vi的重要性。

    3. 矩阵乘法 (AE)⊤Eˉ 是关键步骤：

       - 它的维度是 (n×m)⋅(m×d)=n×d。

       - 对于节点 vi，这个操作实际上是在执行加权求和：
         $$
         xˉ_i=∑_{e_k∈H(v_i)}A_{k,i}^E⋅eˉ_k
         $$
         即，将节点 vi所属的所有超边的特征 eˉk，按其对应的注意力权重 Ak,iE进行聚合。

    4. 最后，同样通过一个激活函数 σ(ELU）引入非线性，得到最终更新后的节点特征矩阵 Xˉ。

- **作用**：**生成节点的新表示**。这个新表示融合了节点所在超边的全局信息和结构信息，并且这种融合是“密度感知”的，更侧重于那些语义明确、结构紧凑的超边所提供的信息。

**公式 (19): 完整的单层密度感知超图注意力层**

- $$
  Xˉ=ELU((A^E)^⊤ ELU((A^V)^⊤X^VW))
  $$

  **推导与含义**：

  - **目的**：将公式 (15) 和公式 (18) 串联起来，形成一个完整的、可堆叠的超图注意力层。
  - **计算过程**：
    1. **内层操作 `ELU(A^{V}^TX^{V}W)`**：这完全对应公式 (15)，即**密度感知的顶点聚合**。输入是节点特征 XV*X**V*，输出是更新后的超边特征 Eˉ*E*ˉ。
    2. **外层操作 `(A^{E})^T `**：这对应公式 (18)，即**密度感知的超边聚合**。它将内层计算得到的超边特征 Eˉ作为输入。
    3. **激活函数**：两次操作之后都使用了 **ELU** 激活函数（论文明确指定，替代了通用的 σ）来引入非线性。

- **作用**：

  - **定义层操作**：明确了一个完整的超图注意力层就是执行一次"节点 -> 超边 -> 节点"的信息传播。
  - **模块化**：使得这个层可以像标准图卷积层一样，被多次堆叠（尽管本文中只用了两层），以捕获更深层次的高阶关系。

------

**公式 (20): 多头注意力机制**
$$
Xˉ=∥_{i=1}^T ELU((A^{E_{(i)}})^⊤ ELU((A^{V(i)})^⊤X^VW^{(i)}))
$$


- **推导与含义**：
  - **目的**：通过**多头注意力（Multi-head Attention）** 机制来稳定和增强学习过程。
  - **计算过程**：
    1. **独立并行计算**：将公式 (19) 的单头注意力重复执行 T*T* 次（T*T* 是头的数量）。每次计算使用**独立的、不同的参数**（不同的权重矩阵 W(i)*W*(*i*) 和注意力向量 aV(i),aE(i)*a**V*(*i*),*a**E*(*i*)，从而产生不同的注意力矩阵 AV(i)*A**V*(*i*) 和 AE(i)*A**E*(*i*)）。
    2. **特征拼接**：每个头都会输出一个更新后的节点特征矩阵 Xˉ(i)∈Rn×d′*X*ˉ(*i*)∈R*n*×*d*′，其中 d′*d*′ 是每个头的输出维度。最后，将所有头的输出在**特征维度上进行拼接**（用 ∥i=1T∥*i*=1*T* 表示），得到最终的节点特征 Xˉ∈Rn×(T⋅d′)*X*ˉ∈R*n*×(*T*⋅*d*′)。
- **作用**：
  - **稳定训练**：多个注意力头可以学习到节点和超边之间不同的相关性模式，然后通过拼接进行融合，使得训练过程更稳定，减少对单一注意力分布的依赖。
  - **增强表达能力**：允许模型在不同的表示子空间（different representation subspaces）中共同关注信息，从而捕获更丰富的特征。论文中提到，第一层使用了2个头的多头注意力。

------

**公式 (21) & (22): 输出与总损失函数**

**公式 (21): 分类损失**
$$
L_{Pred}=−∑_{i∈L}∑_{j=1}^cY_{i,j}ln⁡Z_{i,j}
$$


- **推导与含义**：
  - **目的**：衡量模型在**已标记节点**上的分类性能。
  - **计算过程**：这是一个标准的**多类交叉熵损失**。
    - L是已标记节点的集合。
    - Y∈Rn×c是节点的真实标签（one-hot编码）。
    - Z∈Rn×c是模型的预测输出，通过对最后一层输出的节点特征应用 **softmax 函数** 得到，表示每个节点属于各个类别的概率分布。
    - 损失函数只对带标签的节点 i∈L 进行计算。
- **作用**：这是驱动模型进行正确分类的**主要监督信号**。

**公式 (22): 联合总损失**
$$
L=L_{Learn}+λL_{Pred}
$$


- **推导与含义**：
  - **目的**：将**超图结构学习**（来自4.1节的MVHL网络）和**节点分类任务**（来自4.2节的DAHAT网络）的损失结合起来，进行**联合优化**。
  - **计算过程**：
    - LLearnLLearn 是公式 (8) 定义的超图学习损失，它确保学习到的超图结构具有良好的性质（平滑、稀疏、连通、多视图一致）。
    - LPredLPred 是公式 (21) 的分类损失。
    - λ*λ* 是一个权衡参数，用于平衡两个损失项的重要性。
- **作用**：
  - **端到端学习**：这是MD-HGNN模型的核心思想。通过联合优化，模型学习到的超图结构 H*H* 不仅是数据驱动的，而且是**任务导向的**——它被优化成最有利于下游半监督分类任务的结构。
  - **双向促进**：一个好的超图结构能提升节点表示的质量，从而改善分类性能；同时，分类任务的监督信号也能反过来指导超图结构的学习，使其更能揭示与类别相关的数据关联。

### 4.3贡献

#### **创新点一：多视图超图结构学习 — 解决“图结构不优”的问题**

**目标**：不依赖固定的、可能不准确的初始图，而是从数据中自适应地学习一个最优的超图结构。

**实现公式与流程：**

1. **多视图相似度计算（公式2）**：

   $$
   S_{i,j}^{(k)}=sim_k(xˉ_i,xˉ_j)
   $$
   

   - **创新作用**：摒弃单一相似度度量（如欧氏距离）的局限性。通过多个视图（如余弦相似度、内积）从不同角度计算节点关系，为构建更鲁棒的超图打下基础。

2. **稀疏化与超边构造（公式3, 4）**：

   $$
   S_{i,j}^{(k)}=\begin{cases}
   S_{i,j}^{(k)},S_{i,j}^{(k)}>=δ1\\
   0,S_{i,j}^{(k)}<δ1
   \end{cases}
   $$

   $$
   H_{(k)}=C_{tt}(S~(k))
   $$

   

   - **创新作用**：通过阈值 `δ₁` 进行稀疏化，然后构造超边。这是一个数据驱动的过程，而不是固定的k-NN规则，使得超边结构更能反映真实的数据关联。

3. **多视图融合与一致性约束（公式5, 6）**：

   $$
   H=1/V∑_{i=1}^VH(i)
   $$

   $$
   L_{con}=1/V∑_{i=1}^V∥H(i)−H∥_2^2
   $$

   

   - **创新作用**：
     - **公式5（融合）**：将不同视图得到的超图进行平均，得到一个共识超图，集成了不同相似度度量的优点。
     - **公式6（一致性损失）**：强制不同视图学到的结构彼此相似，作为一种正则化，防止过拟合到某个特定视图的噪声上，提升了泛化能力。

4. **超图学习总损失（公式8）**：

   $$
   L_{Learn}=\frac{a}{n^2}tr⁡(Xˉ^⊤LXˉ)+\fracβ{n^2}∥H∥_F^2−\fracγn1⊤log⁡(H1)+\frac{μ}{n^2}L_{con}
   $$
   
   
   - **创新作用**：该损失函数综合了**平滑性、稀疏性、连通性和一致性**约束，直接指导模型学习一个具有良好数学性质、适合下游任务的超图结构 `H`。

------

#### 创新点二：密度感知超图表示学习 — 解决“忽视隐式信息”的问题

**目标**：在超图神经网络的消息传播中，引入密度这一隐式信息，更智能地聚合信息。

**实现公式与流程：**

1. **密度定义（公式11, 16）**：

   $$
   ρ_i^V=∑_{vj∈N(vi)}\begin{cases}
   sim(x_i^V,x_j^V),if sim(x_i^V,x_j^V)>δ2\\
   0,if sim(x_i^V,x_j^V)≤δ2
   \end{cases}
   $$

   $$
   ρ_k^E=∑_{v_j∈H(e_k)}ρ_j^V
   $$

   

   - **创新作用**：首次在超图上明确定义了节点和超边的“密度”。密度高的节点/超边往往位于类别中心区域，更可靠。这为利用隐式信息提供了量化基础。

2. **密度感知注意力机制（公式14, 17）**：

   $$
   A_{i,k}^V=\frac{exp⁡(LeakyReLU((x_iV^W∥x_k^EW)a_V)+ρ~_i^V)}{∑_{v_j∈H(e_k)}exp⁡(LeakyReLU((x_j^VW∥x_k^EW)a_V)+ρ~_j^V)}
   $$

   $$
   A_{k,i}^E=\frac{exp⁡(LeakyReLU((x_k^EW∥x_i^VW)a_E)+ρ~_k^E)}{ ∑_{e_j∈H(v_i)}exp⁡(LeakyReLU((x_j^EW∥x_i^VW)a_E)+ρ~_j^E)}
   $$

   

   - **创新作用**：这是最核心的创新公式。它将归一化后的密度 `ρ̃` 作为**偏置项**直接添加到注意力分数的计算中。
   - **效果**：在进行节点->超边（或超边->节点）的聚合时，模型会**自动赋予高密度区域更高的权重**。这意味着信息聚合会更侧重于语义一致、可靠的区域，而非稀疏、可能包含噪声的区域。

3. **密度感知特征聚合（公式15, 18, 19）**：

   $$
   Eˉ=σ((A^V)^⊤X^VW)
   $$

   $$
   Xˉ=σ((AE)^⊤Eˉ)
   $$
   
   $$
   Xˉ=ELU((A^E)^⊤ ELU((A^V)^⊤X^VW))
   $$
   
   
   
   - **创新作用**：使用计算好的密度感知注意力权重进行实际的加权求和。完成了“节点->超边->节点”的**高阶、密度引导的信息传播**，生成了更鲁棒、判别力更强的节点表示。

------

#### 创新点三：联合优化 — 实现“结构学习”与“表示学习”的相互促进

**目标**：让学到的超图结构最适合下游的分类任务，同时让表示学习过程能反哺结构学习。

**实现公式：**

**联合总损失函数（公式22）**：

$$
L=L_{Learn}+λL_{Pred}
$$

- **创新作用**：这是整个模型的“大脑”，实现了端到端学习。
  1. **任务导向的结构学习**：梯度会从分类任务 (LPredLPred) 反向传播到超图结构 (`H`)。这意味着模型学习到的不仅是数据本身的结构，更是**对分类任务最有利的结构**。
  2. **结构优化的表示学习**：表示学习模块 (DAHAT) 接收到的是被联合损失优化过的、高质量的超图结构 `H`，从而能学到更好的节点表示。
  3. **闭环反馈**：两个过程相互促进，形成一个良性循环，最终共同优化。

## 5.读Related Work（现状是这部分通常最后完成，不太重要）